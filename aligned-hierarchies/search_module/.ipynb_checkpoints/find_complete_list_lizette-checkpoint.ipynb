{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#def find_complete_list(pair_list,song_length):\n",
    "#    \"\"\"\n",
    "#    Finds all smaller diagonals (and the associated pairs of repeats) \n",
    "#    that are contained in pair_list, which is composed of larger \n",
    "#    diagonals found in find_initial_repeats.\n",
    "        \n",
    "#    Args\n",
    "#    ----\n",
    "#    pair_list: np.array\n",
    "#        list of pairs of repeats found in earlier step\n",
    "#        (bandwidths MUST be in ascending order). If you have\n",
    "#        run find_initial_repeats before this script,\n",
    "#        then pair_list will be ordered correctly. \n",
    "           \n",
    "#    song_length: int\n",
    "#        song length, which is the number of audio shingles.\n",
    "   \n",
    "#    Returns\n",
    "#    -------  \n",
    "#    lst_out: np.array \n",
    "#        list of pairs of repeats with smaller repeats added\n",
    "#    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utilities  \n",
    "from utilities import add_annotations\n",
    "from utilities import __find_song_pattern\n",
    "\n",
    "import search \n",
    "from search import find_add_srows\n",
    "from search import find_add_mrows\n",
    "from search import find_add_erows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs: \n",
    "pair_list = np.array([[1, 15, 31, 45, 15], \n",
    "                      [1, 10, 46, 55, 10], \n",
    "                      [31, 40, 46, 55, 10],\n",
    "                      [10, 20, 40, 50, 15]])\n",
    "song_length = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 15]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Find the list of unique repeat lengths\n",
    "bw_found = np.unique(pair_list[:,4])\n",
    "print(bw_found)\n",
    "bw_num = np.size(bw_found, axis=0)\n",
    "longest_bw = bw_found[-1]\n",
    "print(bw_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the longest bandwidth is the length of the song, then remove that row or rows \n",
    "if song_length == longest_bw: \n",
    "    #Find row or rows that needs to be removed \n",
    "    row = np.where(pair_list[:,4] == longest_bw)\n",
    "    num_row = np.size(row, axis = 1)\n",
    "    #If there are multiple rows that have a bw of the length of the song\n",
    "    if num_row > 1:\n",
    "        #Counter ensures indices will match up with the rows of the current pair_list being worked on \n",
    "        counter = 0\n",
    "        for index in row[0]:\n",
    "            #Finds the index of the row that needs to be removed \n",
    "            row_index = index - counter \n",
    "            #Removes row \n",
    "            pair_list = np.delete(pair_list, row_index, 0)\n",
    "            #Increment counter since pair_list has been transformed \n",
    "            counter = counter + 1  \n",
    "    else:\n",
    "        pair_list = np.delete(pair_list, row[0], 0)\n",
    "    \n",
    "    #Remove longest bandwidth from list of repeat lengths \n",
    "    longest_unique_index = np.where(bw_found == longest_bw)\n",
    "    bw_found = np.delete(bw_found, longest_unique_index, None)\n",
    "    #Decrement number of unique repeat lengths\n",
    "    bw_num = bw_num - np.size(longest_unique_index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j 1\n",
      "[[ 1 15 31 45 15]\n",
      " [ 1 10 46 55 10]\n",
      " [31 40 46 55 10]\n",
      " [10 20 40 50 15]] [ 1 31 46] 10\n",
      "[10 40 55]\n",
      "outputs [array([[ 1, 10, 31, 40, 10],\n",
      "       [11, 15, 41, 45,  5],\n",
      "       [ 1, 10, 31, 40, 10],\n",
      "       [11, 15, 41, 45,  5]])\n",
      " array([False]) array([False])]\n",
      "i 0\n",
      "entered\n",
      "add_mat [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "add_mat [[ 1 10 31 40 10]\n",
      " [11 15 41 45  5]\n",
      " [ 1 10 31 40 10]\n",
      " [11 15 41 45  5]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1. 10. 31. 40. 10.]\n",
      " [11. 15. 41. 45.  5.]\n",
      " [ 1. 10. 31. 40. 10.]\n",
      " [11. 15. 41. 45.  5.]]\n",
      "i 1\n",
      "i 2\n",
      "[[ 1. 10. 31. 40. 10.]\n",
      " [11. 15. 41. 45.  5.]\n",
      " [ 1. 10. 31. 40. 10.]\n",
      " [11. 15. 41. 45.  5.]]\n",
      "j 2\n",
      "[[ 1 15 31 45 15]\n",
      " [ 1 10 46 55 10]\n",
      " [31 40 46 55 10]\n",
      " [10 20 40 50 15]] [ 1 10 31 40 46] 15\n",
      "[10 15 20 40 45 50 55]\n",
      "outputs [[False]\n",
      " [False]\n",
      " [False]]\n",
      "i 0\n",
      "i 1\n",
      "i 2\n",
      "[[ 1. 10. 31. 40. 10.]\n",
      " [11. 15. 41. 45.  5.]\n",
      " [ 1. 10. 31. 40. 10.]\n",
      " [11. 15. 41. 45.  5.]]\n"
     ]
    }
   ],
   "source": [
    "#Tells you essentially how many unique bandwidths there are thus how many times you need to search for diagonals \n",
    "for j in range(1, bw_num + 1):\n",
    "    print(\"j\", j)\n",
    "    # Initalize temp variables\n",
    "    p = np.size(pair_list, axis = 0)\n",
    "    #Set band_width: traverse through each bw found in the list of unique bandwidth \n",
    "    band_width = bw_found[j - 1] \n",
    "    \n",
    "    # Isolate pairs of repeats that are length bandwidth in two steps \n",
    "    # Step 1: Isolate the indices of the starting pairs \n",
    "    starting = np.where(pair_list[:,4] == band_width) \n",
    "    bsnds = starting[0][0] \n",
    "    # Step 2: Isolate the indices of the ending pairs \n",
    "    ending = np.where(pair_list[:,4] > band_width)\n",
    "    \n",
    "    if np.size(ending) == 0:\n",
    "        bends = p\n",
    "    else: \n",
    "        bends = ending[0][0] - 1 \n",
    "    \n",
    "    # Part A1: Isolate all starting time steps of the repeats of length bandwidth\n",
    "    start_I = pair_list[bsnds:bends, 0] # 0 = first column\n",
    "    start_J = pair_list[bsnds:bends, 2] # 2 = second column\n",
    "    all_vec_snds = np.concatenate((start_I, start_J))\n",
    "    int_snds = np.unique(all_vec_snds)\n",
    "    \n",
    "    # Part A2: Isolate all ending time steps of the repeats of length bandwidth\n",
    "    end_I = pair_list[bsnds:bends, 1] # Similar to definition for SI\n",
    "    end_J = pair_list[bsnds:bends, 3] # Similar to definition for SJ\n",
    "    all_vec_ends = np.concatenate((end_I,end_J))\n",
    "    int_ends = np.unique(all_vec_ends)\n",
    "    \n",
    "    # Part B: Use the current diagonal information to search for diagonals \n",
    "    #       of length BW contained in larger diagonals and thus were not\n",
    "    #       detected because they were contained in larger diagonals that\n",
    "    #       were removed by our method of eliminating diagonals in\n",
    "    #       descending order by size\n",
    "    \n",
    "    print(\"rows\", pair_list, int_snds, band_width)\n",
    "    print(\"rows part 2\", int_ends)\n",
    "    add_srows = find_add_srows(pair_list, int_snds, band_width)\n",
    "    add_erows = find_add_mrows(pair_list, int_snds, band_width)\n",
    "    add_mrows = find_add_erows(pair_list, int_ends, band_width)\n",
    "    \n",
    "    #Check if add_srows is empty \n",
    "    outputs = np.array([add_srows, add_erows, add_mrows])\n",
    "    print(\"outputs\", outputs)\n",
    "    #Assembles add_mat \n",
    "    for i in range(0, outputs.shape[0]):\n",
    "        print(\"i\", i)\n",
    "        if outputs[i].all() != False: \n",
    "            print(\"entered\")\n",
    "            col = outputs[i].shape[1]\n",
    "            row = outputs[i].shape[0]\n",
    "            add_mat = np.zeros((row, col))\n",
    "            print(\"add_mat\", add_mat)\n",
    "            add_array = outputs[i]\n",
    "            print(\"add_mat\", add_array)\n",
    "            add_mat = np.vstack([add_mat, add_array])\n",
    "            print(add_mat)\n",
    "        else:\n",
    "            next\n",
    "        new_mat = np.row_stack(add_mat)\n",
    "    \n",
    "    num_row = new_mat.shape[0] / 2\n",
    "    r = int(num_row)\n",
    "    \n",
    "    new_mat = np.delete(new_mat, np.s_[:r], axis = 0)\n",
    "    print(new_mat)\n",
    "    \n",
    "# Step 2: Combine pair_list and new_mat. Make sure that you don't have any\n",
    "#         double rows. Then find the new list of found bandwidths in combine_mat.\n",
    "if new_mat.size != 0:\n",
    "    combo = [pair_list, new_mat]\n",
    "    combine_mat = np.concatenate(combo)\n",
    "    combine_mat = np.unique(combine_mat, axis=0)\n",
    "else:\n",
    "    combine_mat = np.unique(pair_list, axis =0)\n",
    "\n",
    "combine_inds = np.argsort(combine_mat[:,4]) # Return the indices that would sort combine_mat's fourth column\n",
    "combine_mat = combine_mat[combine_inds,:]\n",
    "c = np.size(combine_mat,axis=0)\n",
    "\n",
    "# Again, find the list of unique repeat lengths\n",
    "new_bfound = np.unique(combine_mat[:,4])\n",
    "new_bw_num = np.size(new_bfound,axis=0)\n",
    "\n",
    "full_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[]\n",
      "0\n",
      "temp_anno_lst []\n",
      "song_length 55\n",
      "[[ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]]\n",
      "2\n",
      "[[ 1. 10. 31. 40. 10.]\n",
      " [ 1. 10. 46. 55. 10.]]\n",
      "2\n",
      "temp_anno_lst [[ 1 10 31 40 10  0]\n",
      " [ 1 10 46 55 10  0]]\n",
      "song_length 55\n",
      "[[ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]]\n",
      "3\n",
      "[[ 1. 15. 31. 45. 15.]\n",
      " [10. 20. 40. 50. 15.]]\n",
      "2\n",
      "temp_anno_lst [[ 1 15 31 45 15  0]\n",
      " [10 20 40 50 15  0]]\n",
      "song_length 55\n",
      "[[ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]]\n",
      "[[ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]\n",
      " [ 1 10 46 55 10  1]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Loop over the new list of found bandwidths to add the annotation\n",
    "#         markers to each found pair of repeats\n",
    "for j in range(1, new_bw_num + 1):\n",
    "    print(j)\n",
    "    #Set band_width: traverse through each bw found in the list of unique bandwidth \n",
    "    band_width = new_bfound[j - 1] \n",
    "    # Isolate pairs of repeats that are length bandwidth in two steps \n",
    "    \n",
    "    # Step 1: Isolate the indices of the starting pairs \n",
    "    starting = np.where(combine_mat[:,4] == band_width) \n",
    "    new_bsnds = starting[0][0] \n",
    "    \n",
    "    # Step 2: Isolate the indices of the ending pairs \n",
    "    ending = np.where(combine_mat[:,4] > band_width)\n",
    "    if np.size(ending) == 0:\n",
    "        new_bends = c\n",
    "    else: \n",
    "        new_bends = ending[0][0] - 1\n",
    "        \n",
    "    band_width_mat = np.array((combine_mat[new_bsnds : new_bends,]))\n",
    "    print(band_width_mat)\n",
    "    length_band_width_mat = np.size(band_width_mat,axis=0)\n",
    "    print(length_band_width_mat)\n",
    "    temp_anno_lst = np.concatenate((band_width_mat,(np.zeros((length_band_width_mat,1)))),axis=1).astype(int)\n",
    "    # Part C: Get annotation markers for this bandwidth\n",
    "    temp_anno_lst = np.array(temp_anno_lst, ndmin=2)\n",
    "    print(\"temp_anno_lst\", temp_anno_lst)\n",
    "    print(\"song_length\", song_length)\n",
    "    #temp_anno_lst = add_annotations(temp_anno_lst, song_length)\n",
    "    temp_anno_lst = np.array([[ 1, 10, 46, 55, 10,  1],\n",
    "                              [ 1, 10, 46, 55, 10,  1]])\n",
    "    full_lst.append(temp_anno_lst)\n",
    "    final_lst = np.vstack(full_lst)\n",
    "    print(final_lst)\n",
    "lst_out = final_lst\n",
    "    \n",
    "print(lst_out)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
