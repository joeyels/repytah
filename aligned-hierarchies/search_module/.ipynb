{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#def find_complete_list(pair_list,song_length):\n",
    "#    \"\"\"\n",
    "#    Finds all smaller diagonals (and the associated pairs of repeats) \n",
    "#    that are contained in pair_list, which is composed of larger \n",
    "#    diagonals found in find_initial_repeats.\n",
    "        \n",
    "#    Args\n",
    "#    ----\n",
    "#    pair_list: np.array\n",
    "#        list of pairs of repeats found in earlier step\n",
    "#        (bandwidths MUST be in ascending order). If you have\n",
    "#        run find_initial_repeats before this script,\n",
    "#        then pair_list will be ordered correctly. \n",
    "           \n",
    "#    song_length: int\n",
    "#        song length, which is the number of audio shingles.\n",
    "   \n",
    "#    Returns\n",
    "#    -------  \n",
    "#    lst_out: np.array \n",
    "#        list of pairs of repeats with smaller repeats added\n",
    "#    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs: \n",
    "pair_list = np.array([[1, 15, 31, 45, 15], \n",
    "                      [1, 10, 46, 55, 10], \n",
    "                      [31, 40, 46, 55, 10],\n",
    "                      [10, 20, 40, 50, 15]])\n",
    "song_length = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 15]\n"
     ]
    }
   ],
   "source": [
    "# Find the list of unique repeat lengths\n",
    "bw_found = np.unique(pair_list[:,4])\n",
    "print(bw_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "bw_num = np.size(bw_found, axis=0)\n",
    "print(bw_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_bw = bw_found[-1]\n",
    "longest_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCERNED: How is this finding the row with a bandwith = length of song?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the longest bandwidth is the length of the song, then remove that row or rows \n",
    "if song_length == longest_bw: \n",
    "    #Find row or rows that needs to be removed \n",
    "    row = np.where(pair_list[:,4] == longest_bw)\n",
    "    \n",
    "    #If there are multiple rows that have a bw of the length of the song\n",
    "    if np.size(row, axis = 1) > 1:\n",
    "        #Counter ensures indices will match up with the rows of the current pair_list being worked on \n",
    "        counter = 0\n",
    "        for index in row[0]:\n",
    "            #Finds the index of the row that needs to be removed \n",
    "            row_index = index - counter \n",
    "            #Removes row \n",
    "            pair_list = np.delete(pair_list, row_index, 0)\n",
    "            #Increment counter since pair_list has been transformed \n",
    "            counter = counter + 1  \n",
    "    else:\n",
    "        pair_list = np.delete(pair_list, row[0], 0)\n",
    "    \n",
    "    #Remove longest bandwidth from list of repeat lengths \n",
    "    longest_unique_index = np.where(bw_found == longest_bw)\n",
    "    bw_found = np.delete(bw_found, longest_unique_index, None)\n",
    "\n",
    "    #Decrement number of unique repeat lengths\n",
    "    bw_num = bw_num - np.size(longest_unique_index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Initalize temp variables\n",
    "p = np.size(pair_list, axis = 0)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "add_mat = []\n",
    "print(add_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% Step 1: For each found bandwidth, search upwards (i.e. search the larger \n",
    "%         bandwidths) and add all found diagonals to the variable ADD_MAT\n",
    "\n",
    "for i = 1:b\n",
    "\n",
    "    % Set the bandwidth based on BFOUND\n",
    "    \n",
    "    bw = bfound(i); \n",
    "    \n",
    "    % Isolate pairs of repeats that are length BW\n",
    "    \n",
    "    bsnds = find(pair_lst(:,5) == bw, 1);\n",
    "    bends = find(pair_lst(:,5) > bw, 1) - 1; % This is ok since [] - 1 = []\n",
    "    if isempty(bends)\n",
    "        bends = p;\n",
    "    end\n",
    "    \n",
    "    % Part A1: Isolate all starting time steps of the repeats of length BW\n",
    "    \n",
    "    SI = pair_lst(bsnds:bends,1);\n",
    "    SJ = pair_lst(bsnds:bends,3);\n",
    "    all_vec_snds = [SI;SJ];\n",
    "    int_snds = unique(all_vec_snds);\n",
    "    \n",
    "    % Part A2: Isolate all ending time steps of the repeats of length BW\n",
    "    \n",
    "    EI = pair_lst(bsnds:bends,2); % Similar to definition for SI\n",
    "    EJ = pair_lst(bsnds:bends,4); % Similar to definition for SJ\n",
    "    all_vec_ends = [EI;EJ];\n",
    "    int_ends = unique(all_vec_ends);\n",
    "    \n",
    "    % Part B: Use the current diagonal information to search for diagonals \n",
    "    %         of length BW contained in larger diagonals and thus were not\n",
    "    %         detected because they were contained in larger diagonals that\n",
    "    %         were removed by our method of eliminating diagonals in\n",
    "    %         descending order by size\n",
    "    \n",
    "    [add_srows] = find_add_srows_both_check_no_anno(pair_lst, int_snds, bw);\n",
    "    [add_mrows] = find_add_mrows_both_check_no_anno(pair_lst, int_snds, bw);\n",
    "    [add_erows] = find_add_erows_both_check_no_anno(pair_lst, int_ends, bw);\n",
    "\n",
    "    % Add the new pairs of repeats to the temporary list ADD_MAT\n",
    "    \n",
    "    add_mat = [add_mat; add_srows; add_mrows; add_erows];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tells you essentially how many unique bandwidths there are thus how many times you need search for diagonals \n",
    "for j in range(1, bw_num + 1):\n",
    "    \n",
    "    #Set band_width: traverse through each bw found in the list of unique bandwidth \n",
    "    band_width = bw_found[j - 1] \n",
    "    # Isolate pairs of repeats that are length bandwidth in two steps \n",
    "    \n",
    "    # Step 1: Isolate the indices of the starting pairs \n",
    "    starting = np.where(pair_list[:,4] == band_width) \n",
    "    bsnds = starting[0][0] \n",
    "    \n",
    "    # Step 2: Isolate the indices of the ending pairs \n",
    "    ending = np.where(pair_list[:,4] > band_width)\n",
    "    if np.size(ending) == 0:\n",
    "        bends = p\n",
    "    else: \n",
    "        bends = ending[0][0] - 1 \n",
    "    \n",
    "    # Part A1: Isolate all starting time steps of the repeats of length bandwidth\n",
    "    start_I = pair_list[bsnds:bend, 0] # 0 = first column\n",
    "    start_J = pair_list[bsnds:bend, 2] # 2 = second column\n",
    "    all_vec_snds = np.concatenate((start_I, start_J))\n",
    "    int_snds = np.unique(all_vec_snds)\n",
    "    \n",
    "    # Part A2: Isolate all ending time steps of the repeats of length bandwidth\n",
    "    end_I = pair_list[bsnds:bend, 1] # Similar to definition for SI\n",
    "    end_J = pair_list[bsnds:bend, 3] # Similar to definition for SJ\n",
    "    all_vec_ends = np.concatenate((end_I,end_J))\n",
    "    int_ends = np.unique(all_vec_ends)\n",
    "    \n",
    "    # Part B: Use the current diagonal information to search for diagonals \n",
    "    #       of length BW contained in larger diagonals and thus were not\n",
    "    #       detected because they were contained in larger diagonals that\n",
    "    #       were removed by our method of eliminating diagonals in\n",
    "    #       descending order by size\n",
    "    add_srows = find_add_srows(pair_list, int_snds, band_width)\n",
    "    add_erows = find_add_mrows(pair_list, int_snds, band_width)\n",
    "    add_mrows = find_add_erows(pair_list, int_ends, band_width)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 10 46 55 10]\n",
      " [31 40 46 55 10]]\n",
      "[ 1 31 46]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(pair_list)\n",
    "print(int_snds)\n",
    "print(band_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is bw_found? [10 15]\n",
      "What is bw_num? 2\n",
      "\n",
      "What is p? 4\n",
      "What is band_width? 10\n",
      "What is bsnds? (array([1, 2]),) <class 'numpy.int64'>\n",
      "What is bsnds? 2\n",
      "What is bends--non-array? (array([0, 3]),)\n",
      "What is bends--array? [[0 3]]\n",
      "\n",
      "entered the statement - bend.size > 0\n",
      "np.amin(bend) 0\n",
      "\n",
      "start_I []\n",
      "start_J []\n",
      "all_vec_snds? \n",
      " []\n",
      "\n",
      "all_vec_ends? \n",
      " []\n",
      "What is pair_list? \n",
      " [[ 1 15 31 45 15]\n",
      " [ 1 10 46 55 10]\n",
      " [31 40 46 55 10]\n",
      " [10 20 40 50 15]]\n",
      "What is int_snds? \n",
      " []\n",
      "What is int_ends? \n",
      " []\n",
      "What is bw? \n",
      " 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_add_srows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-583130433e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m \u001b[0mfind_complete_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-583130433e59>\u001b[0m in \u001b[0;36mfind_complete_list\u001b[0;34m(pair_list, song_length)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What is int_ends? \\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint_ends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What is bw? \\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mband_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0madd_srows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_add_srows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_snds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0madd_erows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_add_mrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_snds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0madd_mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_add_erows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_ends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_add_srows' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "        # Part B: Use the current diagonal information to search for diagonals \n",
    "        #       of length BW contained in larger diagonals and thus were not\n",
    "        #       detected because they were contained in larger diagonals that\n",
    "        #       were removed by our method of eliminating diagonals in\n",
    "        #       descending order by size\n",
    "        add_srows = find_add_srows(pair_list, int_snds, band_width)\n",
    "        add_erows = find_add_mrows(pair_list, int_snds, band_width)\n",
    "        add_mrows = find_add_erows(pair_list, int_ends, band_width)\n",
    "        \n",
    "        # Check if any of the arrays are empty, if so, reshape them\n",
    "        ## these are lines I just removed\n",
    "        ##if add_mrows == 0:\n",
    "           ## column = add_srows.shape[1]\n",
    "           ## add_mrows = np.array([],dtype=np.int64).reshape(0,column) \n",
    "        ##if add_srows == 0:\n",
    "           ## column = add_erows.shape[1]\n",
    "            ##add_mrows = np.array([],dtype=np.int64).reshape(0,column) \n",
    "        ##if add_erows == 0:\n",
    "            ##column = add_srows.shape[1]\n",
    "            ##add_mrows = np.array([],dtype=np.int64).reshape(0,column) \n",
    "       \n",
    "        # Add the new pairs of repeats to the temporary list add_mat\n",
    "        add_mat.extend((add_srows,add_erows,add_mrows))\n",
    "        new_mat = np.column_stack(add_mat)\n",
    "      \n",
    "    # Step 2: Combine pair_list and new_mat. Make sure that you don't have any\n",
    "    #         double rows in add_mat. Then find the new list of found \n",
    "    #         bandwidths in combine_mat.\n",
    "    combo = [pair_list,new_mat]\n",
    "    combine_mat = np.concatenate(combo)\n",
    "    combine_mat = np.unique(combine_mat,axis=0)\n",
    "    combine_inds = np.argsort(combine_mat[:,4]) # Return the indices that would sort combine_mat's fourth column\n",
    "    combine_mat = combine_mat[combine_inds,:]\n",
    "    c = np.size(combine_mat,axis=0)\n",
    "    \n",
    "    # Again, find the list of unique repeat lengths\n",
    "    new_bw_found = np.unique(combine_mat[:,4])\n",
    "    new_bw_num = np.size(new_bfound,axis=0)\n",
    "    full_lst = []\n",
    "    \n",
    "    # Step 3: Loop over the new list of found bandwidths to add the annotation\n",
    "    #         markers to each found pair of repeats\n",
    "    for j in range(1,new_bw_num+1):\n",
    "        new_bw = new_bw_found[j-1]\n",
    "        # Isolate pairs of repeats in combine_mat that are length bandwidth\n",
    "        new_bsnds = np.amin((combine_mat[:,4] == new_bw).nonzero()) # Return the minimum of the array\n",
    "        new_bends = (combine_mat[:,4] > new_bw).nonzero() \n",
    "        # Convert new_bends into an array\n",
    "        new_bend = np.array(new_bends)\n",
    "    \n",
    "        if new_bend.size > 0:\n",
    "            new_bend = np.amin(new_bend)\n",
    "        else:\n",
    "            new_bend = c\n",
    "        \n",
    "        band_width_mat = np.array((combine_mat[new_bsnds:new_bend,]))\n",
    "        length_band_width_mat = np.size(band_width_mat,axis=0)\n",
    "        temp_anno_lst = np.concatenate((band_width_mat,(np.zeros((length_band_width_mat,1)))),axis=1).astype(int)\n",
    "        # Part C: Get annotation markers for this bandwidth\n",
    "        temp_anno_lst = add_annotations(temp_anno_lst, song_length)\n",
    "        full_lst.append(temp_anno_lst)\n",
    "        final_lst = np.vstack(full_lst)\n",
    "    \n",
    "    lst_out = final_lst\n",
    "    \n",
    "    return lst_out\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
