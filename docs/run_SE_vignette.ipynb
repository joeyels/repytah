{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64d906b",
   "metadata": {},
   "source": [
    "# The Run_SE Module\n",
    "\n",
    "The `run_SE` module of the `repytah-se` constructs and analyzes Start End (SE) diagrams. The SE diagrams are made from Aligned Hierarchies (AH) and based on Topological Data Analysis. The module allows the user to process directories that hold multiple files and process single files. \n",
    "\n",
    "SE Diagrams are better at comparing songs for the cover song detection task compared to Aligned Hierarchies, whose strength lies in visualization, however the two songs must be the exact same length. Because of this, it is recommended to use SNL Diagrams for this task.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8c6b3",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "The overall pipeline for `repytah-se` is shown below.\n",
    "\n",
    "<img src=\"pictures/SNLflow.jpg\" width=\"380\">\n",
    "\n",
    "\n",
    "\n",
    "To create a distance matrix from SE/SNL diagrams , it is recommended to provide multiple files.\n",
    "\n",
    "You can choose to start from chroma vector files, however you can also start from aligned hierarchies if you have already processed them. There is also the option to process a single file to SE/SNL diagrams or process a directory of multiple files to SE/SNL diagrams and distance matrices. There will be examples provided to help you with the possible options. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153bc9e",
   "metadata": {},
   "source": [
    "## Import Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7aa544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import persim\n",
    "import pkg_resources\n",
    "\n",
    "from run_SE import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b75fd",
   "metadata": {},
   "source": [
    "## Processing a Single File\n",
    "\n",
    "This phase is the integration between `repytah` and `repytah-se`. We create aligned hierarchies from the chroma vectors of a music-based data stream (eg. a song) in `.csv` files. In this step, we choose a threshold value to filter out noise and a number of feature vectors per shingle for contextualization. If running multiple tests with the same threshold and number of feature vectors per shingle values, it is recommended to save the intermediate aligned hierarchies. Please note that while `repytah` contains methods to save aligned hierarchies as `.csv` or `.mat` files, the intermediate aligned hierarchies in this module will be saved in `.mat` format. \n",
    "\n",
    "For more on how aligned hierarchies are created, see `example_vignette.ipynb`.\n",
    "\n",
    "We are using Chopin's Mazurka Op.6, No.1 as input for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de41c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2]\n",
      " [ 49  50]\n",
      " [  2   3]\n",
      " [ 26  27]\n",
      " [ 50  51]\n",
      " [ 74  75]\n",
      " [146 147]\n",
      " [218 219]\n",
      " [290 291]\n",
      " [314 315]\n",
      " [  3   4]\n",
      " [ 51  52]\n",
      " [123 124]\n",
      " [195 196]\n",
      " [291 292]\n",
      " [ 39  40]\n",
      " [231 232]\n",
      " [  1   3]\n",
      " [ 49  51]\n",
      " [  2   4]\n",
      " [ 50  52]\n",
      " [290 292]\n",
      " [ 37  39]\n",
      " [ 85  87]\n",
      " [157 159]\n",
      " [229 231]\n",
      " [ 37  40]\n",
      " [229 232]\n",
      " [  1   4]\n",
      " [ 49  52]\n",
      " [247 251]\n",
      " [271 275]\n",
      " [ 27  37]\n",
      " [ 75  85]\n",
      " [147 157]\n",
      " [219 229]\n",
      " [315 325]\n",
      " [ 26  37]\n",
      " [ 74  85]\n",
      " [146 157]\n",
      " [218 229]\n",
      " [314 325]\n",
      " [ 27  39]\n",
      " [ 75  87]\n",
      " [147 159]\n",
      " [219 231]\n",
      " [ 27  40]\n",
      " [219 232]\n",
      " [ 26  39]\n",
      " [ 74  87]\n",
      " [146 159]\n",
      " [218 231]\n",
      " [ 26  40]\n",
      " [218 232]\n",
      " [  4  26]\n",
      " [ 52  74]\n",
      " [124 146]\n",
      " [196 218]\n",
      " [292 314]\n",
      " [  3  26]\n",
      " [ 51  74]\n",
      " [123 146]\n",
      " [195 218]\n",
      " [291 314]\n",
      " [  4  27]\n",
      " [ 52  75]\n",
      " [124 147]\n",
      " [196 219]\n",
      " [292 315]\n",
      " [  3  27]\n",
      " [ 51  75]\n",
      " [123 147]\n",
      " [195 219]\n",
      " [291 315]\n",
      " [  2  26]\n",
      " [ 50  74]\n",
      " [290 314]\n",
      " [  2  27]\n",
      " [ 50  75]\n",
      " [290 315]\n",
      " [  1  26]\n",
      " [ 49  74]\n",
      " [  1  27]\n",
      " [ 49  75]\n",
      " [  4  37]\n",
      " [ 52  85]\n",
      " [124 157]\n",
      " [196 229]\n",
      " [292 325]\n",
      " [  3  37]\n",
      " [ 51  85]\n",
      " [123 157]\n",
      " [195 229]\n",
      " [291 325]\n",
      " [  4  39]\n",
      " [ 52  87]\n",
      " [124 159]\n",
      " [196 231]\n",
      " [  2  37]\n",
      " [ 50  85]\n",
      " [290 325]\n",
      " [  3  39]\n",
      " [ 51  87]\n",
      " [123 159]\n",
      " [195 231]\n",
      " [  1  37]\n",
      " [ 49  85]\n",
      " [  4  40]\n",
      " [196 232]\n",
      " [ 87 123]\n",
      " [159 195]\n",
      " [  3  40]\n",
      " [195 232]\n",
      " [  2  39]\n",
      " [ 50  87]\n",
      " [ 87 124]\n",
      " [159 196]\n",
      " [  1  39]\n",
      " [ 49  87]\n",
      " [ 85 123]\n",
      " [157 195]\n",
      " [ 85 124]\n",
      " [157 196]\n",
      " [ 75 123]\n",
      " [147 195]\n",
      " [ 75 124]\n",
      " [147 196]\n",
      " [ 74 123]\n",
      " [146 195]\n",
      " [ 74 124]\n",
      " [146 196]\n",
      " [ 87 146]\n",
      " [159 218]\n",
      " [ 87 147]\n",
      " [159 219]\n",
      " [ 85 146]\n",
      " [157 218]\n",
      " [ 85 147]\n",
      " [157 219]\n",
      " [ 87 157]\n",
      " [159 229]\n",
      " [ 75 146]\n",
      " [147 218]\n",
      " [ 52 123]\n",
      " [124 195]\n",
      " [ 87 159]\n",
      " [159 231]\n",
      " [ 51 123]\n",
      " [123 195]\n",
      " [ 52 124]\n",
      " [124 196]\n",
      " [ 74 146]\n",
      " [146 218]\n",
      " [ 75 147]\n",
      " [147 219]\n",
      " [ 85 157]\n",
      " [157 229]]\n"
     ]
    }
   ],
   "source": [
    "# starting from chroma vectors\n",
    "\n",
    "filepath = 'data/input.csv'\n",
    "num_fv_per_shingle = 12\n",
    "thresh = 0.02\n",
    "\n",
    "# default for isChroma is True\n",
    "SE_diagram = get_SEs(filepath, num_fv_per_shingle, thresh, isChroma=True, save=False)\n",
    "\n",
    "print(SE_diagram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e031266b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2]\n",
      " [ 49  50]\n",
      " [  2   3]\n",
      " [ 26  27]\n",
      " [ 50  51]\n",
      " [ 74  75]\n",
      " [146 147]\n",
      " [218 219]\n",
      " [290 291]\n",
      " [314 315]\n",
      " [  3   4]\n",
      " [ 51  52]\n",
      " [123 124]\n",
      " [195 196]\n",
      " [291 292]\n",
      " [ 39  40]\n",
      " [231 232]\n",
      " [  1   3]\n",
      " [ 49  51]\n",
      " [  2   4]\n",
      " [ 50  52]\n",
      " [290 292]\n",
      " [ 37  39]\n",
      " [ 85  87]\n",
      " [157 159]\n",
      " [229 231]\n",
      " [ 37  40]\n",
      " [229 232]\n",
      " [  1   4]\n",
      " [ 49  52]\n",
      " [247 251]\n",
      " [271 275]\n",
      " [ 27  37]\n",
      " [ 75  85]\n",
      " [147 157]\n",
      " [219 229]\n",
      " [315 325]\n",
      " [ 26  37]\n",
      " [ 74  85]\n",
      " [146 157]\n",
      " [218 229]\n",
      " [314 325]\n",
      " [ 27  39]\n",
      " [ 75  87]\n",
      " [147 159]\n",
      " [219 231]\n",
      " [ 27  40]\n",
      " [219 232]\n",
      " [ 26  39]\n",
      " [ 74  87]\n",
      " [146 159]\n",
      " [218 231]\n",
      " [ 26  40]\n",
      " [218 232]\n",
      " [  4  26]\n",
      " [ 52  74]\n",
      " [124 146]\n",
      " [196 218]\n",
      " [292 314]\n",
      " [  3  26]\n",
      " [ 51  74]\n",
      " [123 146]\n",
      " [195 218]\n",
      " [291 314]\n",
      " [  4  27]\n",
      " [ 52  75]\n",
      " [124 147]\n",
      " [196 219]\n",
      " [292 315]\n",
      " [  3  27]\n",
      " [ 51  75]\n",
      " [123 147]\n",
      " [195 219]\n",
      " [291 315]\n",
      " [  2  26]\n",
      " [ 50  74]\n",
      " [290 314]\n",
      " [  2  27]\n",
      " [ 50  75]\n",
      " [290 315]\n",
      " [  1  26]\n",
      " [ 49  74]\n",
      " [  1  27]\n",
      " [ 49  75]\n",
      " [  4  37]\n",
      " [ 52  85]\n",
      " [124 157]\n",
      " [196 229]\n",
      " [292 325]\n",
      " [  3  37]\n",
      " [ 51  85]\n",
      " [123 157]\n",
      " [195 229]\n",
      " [291 325]\n",
      " [  4  39]\n",
      " [ 52  87]\n",
      " [124 159]\n",
      " [196 231]\n",
      " [  2  37]\n",
      " [ 50  85]\n",
      " [290 325]\n",
      " [  3  39]\n",
      " [ 51  87]\n",
      " [123 159]\n",
      " [195 231]\n",
      " [  1  37]\n",
      " [ 49  85]\n",
      " [  4  40]\n",
      " [196 232]\n",
      " [ 87 123]\n",
      " [159 195]\n",
      " [  3  40]\n",
      " [195 232]\n",
      " [  2  39]\n",
      " [ 50  87]\n",
      " [ 87 124]\n",
      " [159 196]\n",
      " [  1  39]\n",
      " [ 49  87]\n",
      " [ 85 123]\n",
      " [157 195]\n",
      " [ 85 124]\n",
      " [157 196]\n",
      " [ 75 123]\n",
      " [147 195]\n",
      " [ 75 124]\n",
      " [147 196]\n",
      " [ 74 123]\n",
      " [146 195]\n",
      " [ 74 124]\n",
      " [146 196]\n",
      " [ 87 146]\n",
      " [159 218]\n",
      " [ 87 147]\n",
      " [159 219]\n",
      " [ 85 146]\n",
      " [157 218]\n",
      " [ 85 147]\n",
      " [157 219]\n",
      " [ 87 157]\n",
      " [159 229]\n",
      " [ 75 146]\n",
      " [147 218]\n",
      " [ 52 123]\n",
      " [124 195]\n",
      " [ 87 159]\n",
      " [159 231]\n",
      " [ 51 123]\n",
      " [123 195]\n",
      " [ 52 124]\n",
      " [124 196]\n",
      " [ 74 146]\n",
      " [146 218]\n",
      " [ 75 147]\n",
      " [147 219]\n",
      " [ 85 157]\n",
      " [157 229]]\n"
     ]
    }
   ],
   "source": [
    "# starting from AH\n",
    "\n",
    "filepath ='data/input.mat'\n",
    "\n",
    "# these values don't matter since starting from AHs\n",
    "num_fv_per_shingle = 12\n",
    "thresh = 0.02\n",
    "\n",
    "SE_diagram = get_SEs(filepath, num_fv_per_shingle, thresh, isChroma=False, save=False)\n",
    "print(SE_diagram)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e905a9",
   "metadata": {},
   "source": [
    "## Processing Multiple Files\n",
    "\n",
    "This module is based on Chopin's Mazurka Dataset, which has expanded and nonexpanded forms for each piece. Thus, the data directories are set up as below. For the smoothest running out of the box, it is recommended that you also organize your files in this fashion, but modified for your purposes.\n",
    "\n",
    "Before running, the directory should look like this:\n",
    "<img src=\"pictures/begin_directoryascii.png\" width=\"300\">\n",
    "\n",
    "If saving intermediate Aligned Hierarchies, the directory will look like this:\n",
    "<img src=\"pictures/after_directoryascii.png\" width=\"380\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382a601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 total SE diagrams in data/chroma_vectors\n",
      "The classes are: ['expanded', 'nonexpanded']\n",
      "The labels for each SE diagram are: [['mazurka06-1', 'mazurka06-2'], ['mazurka06-1', 'mazurka06-2']]\n"
     ]
    }
   ],
   "source": [
    "dir_path ='data/chroma_vectors'\n",
    "\n",
    "num_fv_per_shingle = 12\n",
    "thresh = 0.02\n",
    "\n",
    "# print(dirs)\n",
    "SE_all = get_SE_directory(dir_path, num_fv_per_shingle, thresh, isChroma=True, save=False)\n",
    "print(\"There are {} total SE diagrams in {}\".format((len(SE_all.SEs) * len(SE_all.SEs[0])), dir_path))\n",
    "print(\"The classes are:\", SE_all.className)\n",
    "print(\"The labels for each SE diagram are:\", SE_all.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d20109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(SE_all.SEs))\n",
    "print(len(SE_all.SEs[0]))\n",
    "print(len(SE_all.SEs[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad63ac9",
   "metadata": {},
   "source": [
    "## get_dist_mat\n",
    "\n",
    "This function is used to pairwise compare songs. However, it is recommended to do this with SNL Diagrams instead of SE diagrams because in SNL Diagrams, you can compare two songs of different length. \n",
    "\n",
    "There are two distance metrics to choose from, `'b'` for [bottleneck distance](https://en.wikipedia.org/wiki/Topological_data_analysis) and `'w'` for [Wasserstein distance](https://en.wikipedia.org/wiki/Wasserstein_metric). \n",
    "\n",
    "With a matching truth matrix, you could implement a [kNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b906954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix:\n",
      "[[ 0.  36.  36.  36. ]\n",
      " [36.   0.  21.5 21.5]\n",
      " [36.  21.5  0.  18.5]\n",
      " [36.  21.5 18.5  0. ]]\n",
      "\n",
      "Labels:\n",
      "['mazurka06-1', 'mazurka06-2', 'mazurka06-1', 'mazurka06-2']\n"
     ]
    }
   ],
   "source": [
    "# gives misleading results\n",
    "D, labels = get_dist_mat(SE_all, metric='b')\n",
    "\n",
    "print(\"Distance matrix:\")\n",
    "print(D)\n",
    "\n",
    "# note that because our directory contained expanded and nonexpanded\n",
    "# versions of the same song, there are duplicate names in labels\n",
    "print(\"\\nLabels:\")\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
